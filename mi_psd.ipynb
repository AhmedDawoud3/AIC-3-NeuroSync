{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326f37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac0636e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        index_csv: str,\n",
    "        base_path: str,\n",
    "        ch_names: list,\n",
    "        sfreq: float = 250.0,\n",
    "        transform: callable = None,  # type: ignore\n",
    "    ):\n",
    "        self.base_path = base_path\n",
    "        self.ch_names = ch_names\n",
    "        self.sfreq = sfreq\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load the index CSV\n",
    "        self.df = pd.read_csv(os.path.join(base_path, index_csv))\n",
    "        # the fist half of the dataset\n",
    "        # If 'label' not in test.csv, self.df['label'] will KeyError; handle below.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Determine split\n",
    "        id_num = row[\"id\"]\n",
    "        if id_num <= 4800:\n",
    "            split = \"train\"\n",
    "        elif id_num <= 4900:\n",
    "            split = \"validation\"\n",
    "        else:\n",
    "            split = \"test\"\n",
    "\n",
    "        # Path to session CSV\n",
    "        eeg_path = os.path.join(\n",
    "            self.base_path,\n",
    "            row[\"task\"],\n",
    "            split,\n",
    "            f\"{row['subject_id']}\",\n",
    "            str(row[\"trial_session\"]),\n",
    "            \"EEGdata.csv\",\n",
    "        )\n",
    "\n",
    "        # Load full session\n",
    "        sess_df = pd.read_csv(eeg_path)\n",
    "\n",
    "        # Determine samples per trial\n",
    "        if row[\"task\"] == \"MI\":\n",
    "            samp = 9 * self.sfreq  # 2250\n",
    "        else:  # SSVEP\n",
    "            samp = 7 * self.sfreq  # 1750\n",
    "\n",
    "        n = int(samp)\n",
    "        start = (int(row[\"trial\"]) - 1) * n\n",
    "        end = start + n\n",
    "\n",
    "        # Slice out EEG channels only\n",
    "        data = sess_df[self.ch_names].iloc[start:end].to_numpy().T  # shape (8, n)\n",
    "\n",
    "        # Optional MNE preprocessing\n",
    "        info = mne.create_info(\n",
    "            ch_names=self.ch_names,\n",
    "            sfreq=self.sfreq,\n",
    "            ch_types=[\"eeg\"] * len(self.ch_names),  # type: ignore\n",
    "        )\n",
    "        if self.transform is not None:\n",
    "            with mne.utils.use_log_level(\"WARNING\"):\n",
    "                info = mne.create_info(\n",
    "                    ch_names=self.ch_names,\n",
    "                    sfreq=self.sfreq,\n",
    "                    ch_types=[\"eeg\"] * len(self.ch_names),\n",
    "                )\n",
    "                raw = mne.io.RawArray(data, info)\n",
    "                raw = self.transform(raw)\n",
    "                data = raw.get_data()\n",
    "\n",
    "        # To tensor\n",
    "        eeg_tensor = torch.from_numpy(data).float()\n",
    "\n",
    "        # Return with/without label\n",
    "        if \"label\" in self.df.columns:\n",
    "            label = row[\"label\"]\n",
    "            return eeg_tensor, label\n",
    "        else:\n",
    "            return eeg_tensor\n",
    "\n",
    "\n",
    "class MI_Dataset(EEG_Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_path: str,\n",
    "        index_csv: str,\n",
    "        ch_names: list,\n",
    "        sfreq: float = 250.0,\n",
    "        transform: callable = None,  # type: ignore\n",
    "    ):\n",
    "        super().__init__(\n",
    "            base_path=base_path,\n",
    "            index_csv=index_csv,\n",
    "            ch_names=ch_names,\n",
    "            sfreq=sfreq,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "        self.df = self.df[self.df[\"task\"] == \"MI\"].reset_index(drop=True)\n",
    "\n",
    "\n",
    "class SSVEP_Dataset(EEG_Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_path: str,\n",
    "        index_csv: str,\n",
    "        ch_names: list,\n",
    "        sfreq: float = 250.0,\n",
    "        transform: callable = None,  # type: ignore\n",
    "    ):\n",
    "        super().__init__(\n",
    "            base_path=base_path,\n",
    "            index_csv=index_csv,\n",
    "            ch_names=ch_names,\n",
    "            sfreq=sfreq,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "        self.df = self.df[self.df[\"task\"] == \"SSVEP\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6971e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 2400\n",
      "Number of validation samples: 50\n",
      "\n",
      "Sample EEG tensor shape: torch.Size([1, 3, 2250])\n",
      "Sample label: Right\n"
     ]
    }
   ],
   "source": [
    "# ch_names = [\"FZ\", \"C3\", \"CZ\", \"C4\", \"PZ\", \"PO7\", \"OZ\", \"PO8\"]\n",
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "CH_NAMES = [\"C3\", \"CZ\", \"C4\"]\n",
    "SFREQ = 250.0\n",
    "\n",
    "# --- Load Datasets ---\n",
    "# For simplicity in this example, we won't apply any MNE transforms at the dataset level yet.\n",
    "train_dataset = MI_Dataset(\n",
    "    base_path=\"\",\n",
    "    index_csv=\"train.csv\",\n",
    "    ch_names=CH_NAMES,\n",
    "    sfreq=SFREQ,\n",
    "    transform=lambda raw: raw.notch_filter(\n",
    "        freqs=50.0, picks=\"eeg\", fir_design=\"firwin\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "validation_dataset = MI_Dataset(\n",
    "    base_path=\"\",\n",
    "    index_csv=\"validation.csv\",\n",
    "    ch_names=CH_NAMES,\n",
    "    sfreq=SFREQ,\n",
    "    transform=lambda raw: raw.notch_filter(\n",
    "        freqs=50.0, picks=\"eeg\", fir_design=\"firwin\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# --- Create DataLoaders ---\n",
    "# We can use a batch size of 1 for this kind of feature extraction\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(validation_dataset)}\")\n",
    "\n",
    "# --- Inspect a sample ---\n",
    "eeg_tensor, label = next(iter(train_loader))\n",
    "print(f\"\\nSample EEG tensor shape: {eeg_tensor.shape}\")\n",
    "print(f\"Sample label: {label[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "062dd4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [03:36<00:00, 11.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2400, 69), (2400,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = []\n",
    "y_tr = []\n",
    "with mne.utils.use_log_level(\"WARNING\"):\n",
    "    for i in tqdm(range(len(train_dataset))):\n",
    "        eeg_tensor, label = train_dataset[i]\n",
    "        raw = mne.io.RawArray(\n",
    "            eeg_tensor.numpy(),\n",
    "            mne.create_info(\n",
    "                ch_names=CH_NAMES, sfreq=SFREQ, ch_types=[\"eeg\"] * len(CH_NAMES)\n",
    "            ),\n",
    "        )\n",
    "        # Compute the PSD for the current EEG trial\n",
    "        psds, freqs = raw.compute_psd(\n",
    "            method=\"welch\",\n",
    "            fmin=8.0,\n",
    "            fmax=30.0,  # Ensure this covers your highest harmonic\n",
    "            n_fft=1024,  # Use a larger n_fft for better frequency resolution\n",
    "        ).get_data(return_freqs=True)\n",
    "        # Define frequencies of interest (adjust based on your specific needs)\n",
    "        freqs_of_interest = np.arange(8, 31, 1)  # Example: 8 Hz to 30 Hz in 2 Hz steps\n",
    "        feature_vector = []\n",
    "        for freq in freqs_of_interest:\n",
    "            # Find the index of the closest frequency in the PSD\n",
    "            idx = np.argmin(np.abs(freqs - freq))\n",
    "            # Extract the power spectral density value for that frequency\n",
    "            psd_value = psds[:, idx]\n",
    "            feature_vector.extend(psd_value)\n",
    "                # Append the feature vector and label\n",
    "        X_tr.append(feature_vector)\n",
    "        y_tr.append(0 if label == \"Left\" else 1)\n",
    "        \n",
    "X_tr = np.array(X_tr)\n",
    "y_tr = np.array(y_tr)\n",
    "\n",
    "X_tr.shape, y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c37743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# dev\n",
    "X_dev = []\n",
    "y_dev = []\n",
    "\n",
    "with mne.utils.use_log_level(\"WARNING\"):\n",
    "    for i in tqdm(range(len(validation_dataset))):\n",
    "        eeg_tensor, label = validation_dataset[i]\n",
    "        raw = mne.io.RawArray(\n",
    "            eeg_tensor.numpy(),\n",
    "            mne.create_info(\n",
    "                ch_names=CH_NAMES, sfreq=SFREQ, ch_types=[\"eeg\"] * len(CH_NAMES)\n",
    "            ),\n",
    "        )\n",
    "        # Compute the PSD for the current EEG trial\n",
    "        psds, freqs = raw.compute_psd(\n",
    "            method=\"welch\",\n",
    "            fmin=8.0,\n",
    "            fmax=30.0,  # Ensure this covers your highest harmonic\n",
    "            n_fft=1024,  # Use a larger n_fft for better frequency resolution\n",
    "        ).get_data(return_freqs=True)\n",
    "        # Define frequencies of interest (adjust based on your specific needs)\n",
    "        freqs_of_interest = np.arange(8, 31, 1)  # Example: 8 Hz to 30 Hz in 2 Hz steps\n",
    "        feature_vector = []\n",
    "        for freq in freqs_of_interest:\n",
    "            # Find the index of the closest frequency in the PSD\n",
    "            idx = np.argmin(np.abs(freqs - freq))\n",
    "            # Extract the power spectral density value for that frequency\n",
    "            psd_value = psds[:, idx]\n",
    "            feature_vector.extend(psd_value)\n",
    "            # Append the feature vector and label\n",
    "        X_dev.append(feature_vector)\n",
    "        y_dev.append(0 if label == \"Left\" else 1)\n",
    "\n",
    "X_dev = np.array(X_dev)\n",
    "y_dev = np.array(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0745fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training accuracy: 0.6508\n",
      "KNN Validation accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=9, n_jobs=-1)\n",
    "knn_classifier.fit(X_tr, y_tr)\n",
    "# Evaluate on validation set\n",
    "train_accuracy_knn = knn_classifier.score(X_tr, y_tr)\n",
    "validation_accuracy_knn = knn_classifier.score(X_dev, y_dev)\n",
    "print(f\"KNN Training accuracy: {train_accuracy_knn:.4f}\")\n",
    "print(f\"KNN Validation accuracy: {validation_accuracy_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ce1876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training accuracy (k=2): 0.7692 | Validation accuracy: 0.6800\n",
      "KNN Training accuracy (k=3): 0.7742 | Validation accuracy: 0.4400\n",
      "KNN Training accuracy (k=4): 0.7083 | Validation accuracy: 0.5400\n",
      "KNN Training accuracy (k=5): 0.7004 | Validation accuracy: 0.5600\n",
      "KNN Training accuracy (k=6): 0.6675 | Validation accuracy: 0.6200\n",
      "KNN Training accuracy (k=7): 0.6737 | Validation accuracy: 0.6200\n",
      "KNN Training accuracy (k=8): 0.6512 | Validation accuracy: 0.6200\n",
      "KNN Training accuracy (k=9): 0.6508 | Validation accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 10):\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=i, n_jobs=-1)\n",
    "    knn_classifier.fit(X_tr, y_tr)\n",
    "    # Evaluate on validation set\n",
    "    train_accuracy_knn = knn_classifier.score(X_tr, y_tr)\n",
    "    validation_accuracy_knn = knn_classifier.score(X_dev, y_dev)\n",
    "    print(\n",
    "        f\"KNN Training accuracy (k={i}): {train_accuracy_knn:.4f} | Validation accuracy: {validation_accuracy_knn:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c4e6e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 30/31 [00:17<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1213, number of negative: 1187\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17595\n",
      "[LightGBM] [Info] Number of data points in the train set: 2400, number of used features: 69\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505417 -> initscore=0.021668\n",
      "[LightGBM] [Info] Start training from score 0.021668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:18<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "LGBMClassifier                     0.62               0.63     0.63      0.62   \n",
      "ExtraTreeClassifier                0.60               0.61     0.61      0.60   \n",
      "ExtraTreesClassifier               0.54               0.54     0.54      0.54   \n",
      "KNeighborsClassifier               0.54               0.54     0.54      0.54   \n",
      "RandomForestClassifier             0.54               0.54     0.54      0.54   \n",
      "BernoulliNB                        0.56               0.54     0.54      0.55   \n",
      "PassiveAggressiveClassifier        0.56               0.54     0.54      0.55   \n",
      "SGDClassifier                      0.56               0.53     0.53      0.54   \n",
      "XGBClassifier                      0.52               0.52     0.52      0.52   \n",
      "CalibratedClassifierCV             0.48               0.52     0.52      0.43   \n",
      "NuSVC                              0.56               0.51     0.51      0.46   \n",
      "DummyClassifier                    0.44               0.50     0.50      0.27   \n",
      "QuadraticDiscriminantAnalysis      0.44               0.50     0.50      0.27   \n",
      "AdaBoostClassifier                 0.50               0.50     0.50      0.50   \n",
      "SVC                                0.44               0.47     0.47      0.40   \n",
      "LinearSVC                          0.42               0.47     0.47      0.32   \n",
      "RidgeClassifier                    0.42               0.46     0.46      0.34   \n",
      "RidgeClassifierCV                  0.42               0.46     0.46      0.34   \n",
      "NearestCentroid                    0.44               0.46     0.46      0.42   \n",
      "LogisticRegression                 0.40               0.44     0.44      0.31   \n",
      "LabelSpreading                     0.42               0.44     0.44      0.40   \n",
      "LabelPropagation                   0.42               0.44     0.44      0.40   \n",
      "GaussianNB                         0.42               0.44     0.44      0.40   \n",
      "Perceptron                         0.40               0.43     0.43      0.36   \n",
      "BaggingClassifier                  0.44               0.42     0.42      0.43   \n",
      "DecisionTreeClassifier             0.42               0.42     0.42      0.42   \n",
      "LinearDiscriminantAnalysis         0.36               0.40     0.40      0.28   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "LGBMClassifier                       0.67  \n",
      "ExtraTreeClassifier                  0.04  \n",
      "ExtraTreesClassifier                 0.69  \n",
      "KNeighborsClassifier                 0.03  \n",
      "RandomForestClassifier               1.78  \n",
      "BernoulliNB                          0.02  \n",
      "PassiveAggressiveClassifier          0.04  \n",
      "SGDClassifier                        0.04  \n",
      "XGBClassifier                        0.77  \n",
      "CalibratedClassifierCV               6.70  \n",
      "NuSVC                                0.29  \n",
      "DummyClassifier                      0.02  \n",
      "QuadraticDiscriminantAnalysis        0.09  \n",
      "AdaBoostClassifier                   1.24  \n",
      "SVC                                  0.30  \n",
      "LinearSVC                            1.85  \n",
      "RidgeClassifier                      0.05  \n",
      "RidgeClassifierCV                    0.79  \n",
      "NearestCentroid                      0.03  \n",
      "LogisticRegression                   0.05  \n",
      "LabelSpreading                       0.32  \n",
      "LabelPropagation                     0.19  \n",
      "GaussianNB                           0.02  \n",
      "Perceptron                           0.02  \n",
      "BaggingClassifier                    1.41  \n",
      "DecisionTreeClassifier               0.29  \n",
      "LinearDiscriminantAnalysis           0.68  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier, LazyRegressor\n",
    "\n",
    "lazy_classifier = LazyClassifier(\n",
    "    ignore_warnings=True,\n",
    "    random_state=42,\n",
    ")\n",
    "models, predictions = lazy_classifier.fit(X_tr, X_dev, y_tr, y_dev)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c6930e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Training accuracy: 1.0000\n",
      "RF Validation accuracy: 0.5400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_classifier.fit(X_tr, y_tr)\n",
    "# Evaluate on validation set\n",
    "train_accuracy_rf = rf_classifier.score(X_tr, y_tr)\n",
    "validation_accuracy_rf = rf_classifier.score(X_dev, y_dev)\n",
    "print(f\"RF Training accuracy: {train_accuracy_rf:.4f}\")\n",
    "print(f\"RF Validation accuracy: {validation_accuracy_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ea48750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [00:00<00:05,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best RF Validation accuracy: 0.5600 with max_depth=2 and n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [00:01<00:05,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best RF Validation accuracy: 0.6400 with max_depth=3 and n_estimators=50\n",
      "New best RF Validation accuracy: 0.6800 with max_depth=3 and n_estimators=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:06<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Validation accuracy: 0.6800 with max_depth=3 and n_estimators=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grid = [(d, n) for d in range(2, 10) for n in range(50, 101, 20)]\n",
    "best = [0]\n",
    "for d, n in tqdm(grid):\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        n_estimators=n, max_depth=d, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    rf_classifier.fit(X_tr, y_tr)\n",
    "    # Evaluate on validation set\n",
    "    train_accuracy_rf = rf_classifier.score(X_tr, y_tr)\n",
    "    validation_accuracy_rf = rf_classifier.score(X_dev, y_dev)\n",
    "    if validation_accuracy_rf > best[0]:\n",
    "        best = [validation_accuracy_rf, d, n]\n",
    "        print(\n",
    "            f\"New best RF Validation accuracy: {validation_accuracy_rf:.4f} with max_depth={d} and n_estimators={n}\"\n",
    "        )\n",
    "print(\n",
    "    f\"Best RF Validation accuracy: {best[0]:.4f} with max_depth={best[1]} and n_estimators={best[2]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96cd64e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [03:47<00:00, 10.56it/s]\n"
     ]
    }
   ],
   "source": [
    "window = np.hamming(2250)\n",
    "\n",
    "X_fft = []\n",
    "y_fft = []\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    eeg_tensor, label = train_dataset[i]\n",
    "    x = eeg_tensor.numpy().T * window[:, None]  # Apply Hamming window\n",
    "    fft_vals = np.fft.rfft(x, axis=0)\n",
    "    freqs = np.fft.rfftfreq(2250, d=1/250)\n",
    "    mask = (freqs >= 8) & (freqs <= 30)\n",
    "    spectrum = fft_vals[mask, :]\n",
    "    x_features = spectrum.flatten().real  # (n_bins * n_channels,)\n",
    "    X_fft.append(x_features)\n",
    "    y_fft.append(label)\n",
    "    \n",
    "X_fft = np.array(X_fft)\n",
    "y_fft = np.array(y_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0900cadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 597), (2400,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fft.shape, y_fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "387ce4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fft = np.array([0 if label == \"Left\" else 1 for label in y_fft])\n",
    "y_fft_dev = np.array([0 if label == \"Left\" else 1 for label in y_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d85e5bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 11.21it/s]\n"
     ]
    }
   ],
   "source": [
    "X_fft_dev = []\n",
    "y_fft_dev = []\n",
    "for i in tqdm(range(len(validation_dataset))):\n",
    "    eeg_tensor, label = validation_dataset[i]\n",
    "    x = eeg_tensor.numpy().T * window[:, None]  # Apply Hamming window\n",
    "    fft_vals = np.fft.rfft(x, axis=0)\n",
    "    freqs = np.fft.rfftfreq(2250, d=1/250)\n",
    "    mask = (freqs >= 8) & (freqs <= 30)\n",
    "    spectrum = fft_vals[mask, :]\n",
    "    x_features = spectrum.flatten().real  # (n_bins * n_channels,)\n",
    "    X_fft_dev.append(x_features)\n",
    "    y_fft_dev.append(label)\n",
    "X_fft_dev = np.array(X_fft_dev)\n",
    "y_fft_dev = np.array(y_fft_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f0a2571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_fft != y_tr).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ccfb5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 666), (50, 666), (2400,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_big = np.concatenate((X_tr, X_fft), axis=1)\n",
    "X_big_dev = np.concatenate((X_dev, X_fft_dev), axis=1)\n",
    "\n",
    "X_big.shape, X_big_dev.shape, y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c8ff840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training accuracy: 0.6396\n",
      "KNN Validation accuracy: 0.4200\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=9, n_jobs=-1)\n",
    "knn_classifier.fit(X_big, y_tr)\n",
    "# Evaluate on validation set\n",
    "train_accuracy_knn = knn_classifier.score(X_big, y_tr)\n",
    "validation_accuracy_knn = knn_classifier.score(X_big_dev, y_dev)\n",
    "print(f\"KNN Training accuracy: {train_accuracy_knn:.4f}\")\n",
    "print(f\"KNN Validation accuracy: {validation_accuracy_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d5a9711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training accuracy (k=2): 0.7692 | Validation accuracy: 0.7200\n",
      "KNN Training accuracy (k=4): 0.7104 | Validation accuracy: 0.5400\n",
      "KNN Training accuracy (k=6): 0.6833 | Validation accuracy: 0.4800\n",
      "KNN Training accuracy (k=8): 0.6417 | Validation accuracy: 0.5200\n",
      "KNN Training accuracy (k=10): 0.6346 | Validation accuracy: 0.5200\n",
      "KNN Training accuracy (k=12): 0.6317 | Validation accuracy: 0.4800\n",
      "KNN Training accuracy (k=14): 0.6058 | Validation accuracy: 0.5000\n",
      "KNN Training accuracy (k=16): 0.6092 | Validation accuracy: 0.4600\n",
      "KNN Training accuracy (k=18): 0.6025 | Validation accuracy: 0.4600\n"
     ]
    }
   ],
   "source": [
    "for k in range(2, 20, 2):\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n",
    "    knn_classifier.fit(X_big, y_tr)\n",
    "    # Evaluate on validation set\n",
    "    train_accuracy_knn = knn_classifier.score(X_big, y_tr)\n",
    "    validation_accuracy_knn = knn_classifier.score(X_big_dev, y_dev)\n",
    "    print(\n",
    "        f\"KNN Training accuracy (k={k}): {train_accuracy_knn:.4f} | Validation accuracy: {validation_accuracy_knn:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c0618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training accuracy: 0.7692\n",
      "KNN Validation accuracy: 0.7200\n"
     ]
    }
   ],
   "source": [
    "# KNN Training accuracy (k=2): 0.9992 | Validation accuracy: 0.8000\n",
    "knn = KNeighborsClassifier(n_neighbors=2, n_jobs=-1)\n",
    "knn.fit(X_big, y_tr)\n",
    "# Evaluate on validation set\n",
    "train_accuracy_knn = knn.score(X_big, y_tr)\n",
    "validation_accuracy_knn = knn.score(X_big_dev, y_dev)\n",
    "print(f\"KNN Training accuracy: {train_accuracy_knn:.4f}\")\n",
    "print(f\"KNN Validation accuracy: {validation_accuracy_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68fc01bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left       0.68      0.93      0.79        28\n",
      "       Right       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.72        50\n",
      "   macro avg       0.76      0.69      0.69        50\n",
      "weighted avg       0.75      0.72      0.70        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classificaion report\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = knn.predict(X_big_dev)\n",
    "print(classification_report(y_dev, y_pred, target_names=[\"Left\", \"Right\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff94c96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:00<00:05,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best RF Validation accuracy: 0.4200 with max_depth=2 and n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 10/24 [00:03<00:05,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best RF Validation accuracy: 0.4600 with max_depth=5 and n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 11/24 [00:03<00:05,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best RF Validation accuracy: 0.4800 with max_depth=5 and n_estimators=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 14/24 [00:05<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best RF Validation accuracy: 0.5000 with max_depth=6 and n_estimators=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 16/24 [00:06<00:03,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best RF Validation accuracy: 0.5200 with max_depth=7 and n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 20/24 [00:08<00:02,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best RF Validation accuracy: 0.5400 with max_depth=8 and n_estimators=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 21/24 [00:09<00:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best RF Validation accuracy: 0.5600 with max_depth=8 and n_estimators=90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:11<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Validation accuracy: 0.5600 with max_depth=8 and n_estimators=90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grid = [(d, n) for d in range(2, 10) for n in range(50, 101, 20)]\n",
    "best = [0]\n",
    "for d, n in tqdm(grid):\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        n_estimators=n, max_depth=d, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    rf_classifier.fit(X_big, y_tr)\n",
    "    # Evaluate on validation set\n",
    "    train_accuracy_rf = rf_classifier.score(X_big, y_tr)\n",
    "    validation_accuracy_rf = rf_classifier.score(X_big_dev, y_dev)\n",
    "    if validation_accuracy_rf > best[0]:\n",
    "        best = [validation_accuracy_rf, d, n]\n",
    "        print(\n",
    "            f\"New best RF Validation accuracy: {validation_accuracy_rf:.4f} with max_depth={d} and n_estimators={n}\"\n",
    "        )\n",
    "print(\n",
    "    f\"Best RF Validation accuracy: {best[0]:.4f} with max_depth={best[1]} and n_estimators={best[2]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "576a3492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 30/31 [03:21<00:02,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1213, number of negative: 1187\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 169830\n",
      "[LightGBM] [Info] Number of data points in the train set: 2400, number of used features: 666\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505417 -> initscore=0.021668\n",
      "[LightGBM] [Info] Start training from score 0.021668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [03:24<00:00,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "SGDClassifier                      0.66               0.67     0.67      0.66   \n",
      "LinearSVC                          0.66               0.66     0.66      0.66   \n",
      "LogisticRegression                 0.62               0.62     0.62      0.62   \n",
      "KNeighborsClassifier               0.60               0.59     0.59      0.60   \n",
      "BaggingClassifier                  0.62               0.59     0.59      0.60   \n",
      "RidgeClassifierCV                  0.58               0.59     0.59      0.58   \n",
      "DecisionTreeClassifier             0.58               0.58     0.58      0.58   \n",
      "BernoulliNB                        0.56               0.57     0.57      0.56   \n",
      "ExtraTreesClassifier               0.56               0.57     0.57      0.56   \n",
      "RidgeClassifier                    0.56               0.57     0.57      0.56   \n",
      "Perceptron                         0.58               0.56     0.56      0.57   \n",
      "ExtraTreeClassifier                0.52               0.53     0.53      0.52   \n",
      "AdaBoostClassifier                 0.52               0.52     0.52      0.52   \n",
      "PassiveAggressiveClassifier        0.54               0.52     0.52      0.52   \n",
      "LabelPropagation                   0.54               0.52     0.52      0.52   \n",
      "NearestCentroid                    0.48               0.51     0.51      0.45   \n",
      "XGBClassifier                      0.52               0.51     0.51      0.52   \n",
      "DummyClassifier                    0.44               0.50     0.50      0.27   \n",
      "LGBMClassifier                     0.50               0.50     0.50      0.50   \n",
      "LabelSpreading                     0.52               0.49     0.49      0.50   \n",
      "LinearDiscriminantAnalysis         0.48               0.49     0.49      0.48   \n",
      "QuadraticDiscriminantAnalysis      0.46               0.48     0.48      0.45   \n",
      "NuSVC                              0.48               0.47     0.47      0.48   \n",
      "CalibratedClassifierCV             0.40               0.44     0.44      0.31   \n",
      "GaussianNB                         0.42               0.44     0.44      0.40   \n",
      "SVC                                0.42               0.44     0.44      0.40   \n",
      "RandomForestClassifier             0.36               0.34     0.34      0.34   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "SGDClassifier                        0.24  \n",
      "LinearSVC                           28.30  \n",
      "LogisticRegression                   0.29  \n",
      "KNeighborsClassifier                 0.21  \n",
      "BaggingClassifier                   10.04  \n",
      "RidgeClassifierCV                    8.13  \n",
      "DecisionTreeClassifier               2.12  \n",
      "BernoulliNB                          0.12  \n",
      "ExtraTreesClassifier                 2.24  \n",
      "RidgeClassifier                      0.56  \n",
      "Perceptron                           0.17  \n",
      "ExtraTreeClassifier                  0.15  \n",
      "AdaBoostClassifier                  10.20  \n",
      "PassiveAggressiveClassifier          0.17  \n",
      "LabelPropagation                     0.98  \n",
      "NearestCentroid                      0.12  \n",
      "XGBClassifier                        8.23  \n",
      "DummyClassifier                      0.10  \n",
      "LGBMClassifier                       3.36  \n",
      "LabelSpreading                       0.59  \n",
      "LinearDiscriminantAnalysis          19.46  \n",
      "QuadraticDiscriminantAnalysis        1.35  \n",
      "NuSVC                                3.30  \n",
      "CalibratedClassifierCV              96.97  \n",
      "GaussianNB                           0.12  \n",
      "SVC                                  2.81  \n",
      "RandomForestClassifier               4.46  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lazy classifier\n",
    "lazy_classifier = LazyClassifier(\n",
    "    ignore_warnings=True,\n",
    "    random_state=42,\n",
    ")\n",
    "models, predictions = lazy_classifier.fit(X_big, X_big_dev, y_tr, y_dev)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa5c27a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sgd_classifier = LogisticRegression(\n",
    "    solver=\"saga\", max_iter=1000, random_state=42, n_jobs=-1\n",
    ")\n",
    "sgd_classifier.fit(X_big, y_tr)\n",
    "# Evaluate on validation set\n",
    "train_accuracy_sgd = sgd_classifier.score(X_big, y_tr)\n",
    "validation_accuracy_sgd = sgd_classifier.score(X_big_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c317d5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Training accuracy: 0.5679\n",
      "SGD Validation accuracy: 0.5400\n"
     ]
    }
   ],
   "source": [
    "print(f\"SGD Training accuracy: {train_accuracy_sgd:.4f}\")\n",
    "print(f\"SGD Validation accuracy: {validation_accuracy_sgd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4798632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training accuracy: 0.9962\n",
      "XGBoost Validation accuracy: 0.6200\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "xg = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "xg.fit(X_big, y_tr)\n",
    "# Evaluate on validation set\n",
    "train_accuracy_xg = xg.score(X_big, y_tr)\n",
    "validation_accuracy_xg = xg.score(X_big_dev, y_dev)\n",
    "print(f\"XGBoost Training accuracy: {train_accuracy_xg:.4f}\")\n",
    "print(f\"XGBoost Validation accuracy: {validation_accuracy_xg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35949563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:01<00:38,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best XGBoost Validation accuracy: 0.4600 with max_depth=2 and n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [00:03<00:34,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best XGBoost Validation accuracy: 0.4800 with max_depth=2 and n_estimators=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 3/24 [00:05<00:36,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best XGBoost Validation accuracy: 0.5400 with max_depth=2 and n_estimators=90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7/24 [00:13<00:34,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best XGBoost Validation accuracy: 0.6400 with max_depth=4 and n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [03:12<00:00,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Validation accuracy: 0.6400 with max_depth=4 and n_estimators=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grid = [(d, n) for d in range(2, 10) for n in range(50, 101, 20)]\n",
    "best = [0]\n",
    "for d, n in tqdm(grid):\n",
    "    xg = XGBClassifier(\n",
    "        n_estimators=n,\n",
    "        max_depth=d,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    xg.fit(X_big, y_tr)\n",
    "    # Evaluate on validation set\n",
    "    train_accuracy_xg = xg.score(X_big, y_tr)\n",
    "    validation_accuracy_xg = xg.score(X_big_dev, y_dev)\n",
    "    if validation_accuracy_xg > best[0]:\n",
    "        best = [validation_accuracy_xg, d, n]\n",
    "        print(\n",
    "            f\"New best XGBoost Validation accuracy: {validation_accuracy_xg:.4f} with max_depth={d} and n_estimators={n}\"\n",
    "        )\n",
    "print(\n",
    "    f\"Best XGBoost Validation accuracy: {best[0]:.4f} with max_depth={best[1]} and n_estimators={best[2]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f19bd093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Training accuracy: 0.7833\n",
      "Voting Classifier Validation accuracy: 0.6200\n"
     ]
    }
   ],
   "source": [
    "# ensamble with KNN\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"knn\", knn),\n",
    "        # (\"rf\", rf_classifier),\n",
    "        (\"sgd\", sgd_classifier),\n",
    "        # (\"xg\", xg),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "voting_classifier.fit(X_big, y_tr)\n",
    "# Evaluate on validation set\n",
    "train_accuracy_voting = voting_classifier.score(X_big, y_tr)\n",
    "validation_accuracy_voting = voting_classifier.score(X_big_dev, y_dev)\n",
    "print(f\"Voting Classifier Training accuracy: {train_accuracy_voting:.4f}\")\n",
    "print(f\"Voting Classifier Validation accuracy: {validation_accuracy_voting:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e974ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left       0.68      0.93      0.79        28\n",
      "       Right       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.72        50\n",
      "   macro avg       0.76      0.69      0.69        50\n",
      "weighted avg       0.75      0.72      0.70        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "y_pred = knn.predict(X_big_dev)\n",
    "print(classification_report(y_dev, y_pred, target_names=[\"Left\", \"Right\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f9b82710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7000356506238858"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "f1_score(y_dev, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac6eb730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape: (50, 666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load test dataset\n",
    "test_dataset = MI_Dataset(\n",
    "    base_path=\"\",\n",
    "    index_csv=\"test.csv\",\n",
    "    ch_names=CH_NAMES,\n",
    "    sfreq=SFREQ,\n",
    "    transform=lambda raw: raw.notch_filter(\n",
    "        freqs=50.0, picks=\"eeg\", fir_design=\"firwin\"\n",
    "    ),\n",
    ")\n",
    "X_test = []\n",
    "\n",
    "with mne.utils.use_log_level(\"WARNING\"):\n",
    "    for i in tqdm(range(len(test_dataset))):\n",
    "        eeg_tensor = test_dataset[i]\n",
    "        raw = mne.io.RawArray(\n",
    "            eeg_tensor.numpy(),\n",
    "            mne.create_info(\n",
    "                ch_names=CH_NAMES, sfreq=SFREQ, ch_types=[\"eeg\"] * len(CH_NAMES)\n",
    "            ),\n",
    "        )\n",
    "        # Compute the PSD for the current EEG trial\n",
    "        psds, freqs = raw.compute_psd(\n",
    "            method=\"welch\",\n",
    "            fmin=8.0,\n",
    "            fmax=30.0,  # Ensure this covers your highest harmonic\n",
    "            n_fft=1024,  # Use a larger n_fft for better frequency resolution\n",
    "        ).get_data(return_freqs=True)\n",
    "        # Define frequencies of interest (adjust based on your specific needs)\n",
    "        freqs_of_interest = np.arange(8, 31, 1)  # Example: 8 Hz to 30 Hz in 2 Hz steps\n",
    "        feature_vector = []\n",
    "        for freq in freqs_of_interest:\n",
    "            # Find the index of the closest frequency in the PSD\n",
    "            idx = np.argmin(np.abs(freqs - freq))\n",
    "            # Extract the power spectral density value for that frequency\n",
    "            psd_value = psds[:, idx]\n",
    "            feature_vector.extend(psd_value)\n",
    "\n",
    "        x = eeg_tensor.numpy().T * window[:, None]  # Apply Hamming window\n",
    "        fft_vals = np.fft.rfft(x, axis=0)\n",
    "        freqs = np.fft.rfftfreq(2250, d=1 / 250)\n",
    "        mask = (freqs >= 8) & (freqs <= 30)\n",
    "        spectrum = fft_vals[mask, :]\n",
    "        x_features = spectrum.flatten().real  # (n_bins * n_channels,)\n",
    "\n",
    "        # Combine PSD and FFT features\n",
    "        combined_features = np.concatenate((feature_vector, x_features))\n",
    "        X_test.append(combined_features)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "print(f\"Test dataset shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e0b9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = knn.predict(X_test)\n",
    "predictions = [\"Left\" if pred == 0 else \"Right\" for pred in predictions]\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"id\": test_dataset.df[\"id\"],\n",
    "    \"label\": predictions\n",
    "})\n",
    "predictions_df.to_csv(\"predictions_KNN_MI.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d8f60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
